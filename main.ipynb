{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.segmentation import DiceScore \n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n",
    "import albumentations as A\n",
    "import lightning as L\n",
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilPrithvi(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        teacher,\n",
    "        student,\n",
    "        soft_loss_func,\n",
    "        hard_loss_func,\n",
    "        soft_loss_weight=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher.eval()\n",
    "        self.student = student\n",
    "        self.soft_loss_func = soft_loss_func\n",
    "        self.hard_loss_func = hard_loss_func\n",
    "        self.soft_loss_weight = soft_loss_weight\n",
    "\n",
    "        self.dice = DiceScore(num_classes=1)\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.student(image)[\"out\"]\n",
    "\n",
    "    def step(self, batch, stage):\n",
    "        image = batch[\"image\"]\n",
    "        mask = batch[\"mask\"].unsqueeze(1).float()\n",
    "\n",
    "        y = self.forward(image)\n",
    "        y = torch.sigmoid(y)\n",
    "\n",
    "        loss = self.hard_loss_func(y, mask)\n",
    "\n",
    "        self.log(f\"{stage}_loss\", loss, on_epoch=True)\n",
    "        self.log(f\"{stage}_dice\", self.dice(y, mask), on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student(num_channels):\n",
    "    model = deeplabv3_mobilenet_v3_large(\n",
    "        weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT,\n",
    "    )\n",
    "    model.backbone[\"0\"][0] = nn.Conv2d(\n",
    "        num_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
    "    )\n",
    "    model.classifier[4] = nn.Conv2d(\n",
    "        256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = GenericNonGeoSegmentationDataModule(\n",
    "    batch_size=40,\n",
    "    num_workers=8,\n",
    "    dataset_bands=[\n",
    "        \"BLUE\",\n",
    "        \"GREEN\",\n",
    "        \"RED\",\n",
    "        \"NIR_NARROW\",\n",
    "        \"SWIR_1\",\n",
    "        \"SWIR_2\",\n",
    "    ],\n",
    "    output_bands=[\n",
    "        \"BLUE\",\n",
    "        \"GREEN\",\n",
    "        \"RED\",\n",
    "        \"NIR_NARROW\",\n",
    "        \"SWIR_1\",\n",
    "        \"SWIR_2\",\n",
    "    ],\n",
    "    rgb_indices=[2, 1, 0],\n",
    "    train_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    val_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    test_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    train_split=\"datasets/hls_burn_scars/splits/train.txt\",\n",
    "    val_split=\"datasets/hls_burn_scars/splits/val.txt\",\n",
    "    test_split=\"datasets/hls_burn_scars/splits/test.txt\",\n",
    "    img_grep=\"*_merged.tif\",\n",
    "    label_grep=\"*.mask.tif\",\n",
    "    means=[\n",
    "        0.033349706741586264,\n",
    "        0.05701185520536176,\n",
    "        0.05889748132001316,\n",
    "        0.2323245113436119,\n",
    "        0.1972854853760658,\n",
    "        0.11944914225186566,\n",
    "    ],\n",
    "    stds=[\n",
    "        0.02269135568823774,\n",
    "        0.026807560223070237,\n",
    "        0.04004109844362779,\n",
    "        0.07791732423672691,\n",
    "        0.08708738838140137,\n",
    "        0.07241979477437814,\n",
    "    ],\n",
    "    num_classes=2,\n",
    "    train_transform=[A.D4(), A.pytorch.ToTensorV2()],\n",
    "    test_transform=[A.pytorch.ToTensorV2()],\n",
    "    no_data_replace=0,\n",
    "    no_label_replace=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace with an actual teacher model\n",
    "teacher = get_student(num_channels=len(datamodule.output_bands))\n",
    "student = get_student(num_channels=len(datamodule.output_bands))\n",
    "\n",
    "distilprithvi = DistilPrithvi(\n",
    "    teacher=teacher,\n",
    "    student=student,\n",
    "    soft_loss_func=torch.nn.BCEWithLogitsLoss(),\n",
    "    hard_loss_func=torch.nn.BCEWithLogitsLoss(),\n",
    "    soft_loss_weight=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/06 22:13:09 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.8.0.dev20250406+cu128. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n",
      "2025/04/06 22:13:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/mlflow/pytorch/_lightning_autolog.py:465: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.5.0.post0 and may not succeed with packages outside this range.\"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | teacher        | DeepLabV3         | 11.0 M | eval \n",
      "1 | student        | DeepLabV3         | 11.0 M | train\n",
      "2 | soft_loss_func | BCEWithLogitsLoss | 0      | train\n",
      "3 | hard_loss_func | BCEWithLogitsLoss | 0      | train\n",
      "4 | dice           | DiceScore         | 0      | train\n",
      "-------------------------------------------------------------\n",
      "22.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.0 M    Total params\n",
      "88.197    Total estimated model params size (MB)\n",
      "291       Modules in train mode\n",
      "288       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58:  46%|████▌     | 6/13 [05:02<05:53,  0.02it/s, v_num=38]         \n",
      "Epoch 23:  77%|███████▋  | 10/13 [00:06<00:01,  1.58it/s, v_num=40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60:   0%|          | 0/13 [00:00<?, ?it/s, v_num=40]         "
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    trainer.fit(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
