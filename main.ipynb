{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n",
    "import albumentations as A\n",
    "import lightning as L\n",
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilPrithvi(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        teacher,\n",
    "        student,\n",
    "        soft_loss_func,\n",
    "        hard_loss_func,\n",
    "        soft_loss_weight=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.hard_loss_func = hard_loss_func\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.student(image)['out']\n",
    "\n",
    "    def step(self, batch):\n",
    "        image = batch[\"image\"]\n",
    "        mask = batch[\"mask\"].unsqueeze(1).float()\n",
    "        y = self.forward(image)\n",
    "        loss = self.hard_loss_func(y, mask)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student(num_channels, num_classes):\n",
    "    student = deeplabv3_mobilenet_v3_large(\n",
    "        num_classes=num_classes,\n",
    "        # TODO: make transfer learning work\n",
    "        # weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT,\n",
    "    )\n",
    "    student.backbone[\"0\"][0] = nn.Conv2d(\n",
    "        num_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
    "    )\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilprithvi = DistilPrithvi(\n",
    "    teacher=get_student(6, 1),\n",
    "    student=get_student(6, 1),\n",
    "    soft_loss_func=torch.nn.BCEWithLogitsLoss(),\n",
    "    hard_loss_func=torch.nn.BCEWithLogitsLoss(),\n",
    "    soft_loss_weight=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_burn_scars = GenericNonGeoSegmentationDataModule(\n",
    "    batch_size=8,\n",
    "    num_workers=8,\n",
    "    dataset_bands=[\n",
    "        \"BLUE\",\n",
    "        \"GREEN\",\n",
    "        \"RED\",\n",
    "        \"NIR_NARROW\",\n",
    "        \"SWIR_1\",\n",
    "        \"SWIR_2\",\n",
    "    ],\n",
    "    output_bands=[\n",
    "        \"BLUE\",\n",
    "        \"GREEN\",\n",
    "        \"RED\",\n",
    "        \"NIR_NARROW\",\n",
    "        \"SWIR_1\",\n",
    "        \"SWIR_2\",\n",
    "    ],\n",
    "    rgb_indices=[2, 1, 0],\n",
    "    train_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    val_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    test_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    train_split=\"datasets/hls_burn_scars/splits/train.txt\",\n",
    "    val_split=\"datasets/hls_burn_scars/splits/val.txt\",\n",
    "    test_split=\"datasets/hls_burn_scars/splits/test.txt\",\n",
    "    img_grep=\"*_merged.tif\",\n",
    "    label_grep=\"*.mask.tif\",\n",
    "    means=[\n",
    "        0.033349706741586264,\n",
    "        0.05701185520536176,\n",
    "        0.05889748132001316,\n",
    "        0.2323245113436119,\n",
    "        0.1972854853760658,\n",
    "        0.11944914225186566,\n",
    "    ],\n",
    "    stds=[\n",
    "        0.02269135568823774,\n",
    "        0.026807560223070237,\n",
    "        0.04004109844362779,\n",
    "        0.07791732423672691,\n",
    "        0.08708738838140137,\n",
    "        0.07241979477437814,\n",
    "    ],\n",
    "    num_classes=2,\n",
    "    train_transform=[A.D4(), A.pytorch.ToTensorV2()],\n",
    "    test_transform=[A.pytorch.ToTensorV2()],\n",
    "    no_data_replace=0,\n",
    "    no_label_replace=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=20,\n",
    "    val_check_interval=0.5,\n",
    "    default_root_dir=\"checkpoints\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    distilprithvi,\n",
    "    hls_burn_scars,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
