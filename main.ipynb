{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.segmentation import DiceScore \n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n",
    "import albumentations as A\n",
    "import lightning as L\n",
    "from terratorch.models import EncoderDecoderFactory\n",
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = GenericNonGeoSegmentationDataModule(\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    dataset_bands=[\n",
    "        \"BLUE\",\n",
    "        \"GREEN\",\n",
    "        \"RED\",\n",
    "        \"NIR_NARROW\",\n",
    "        \"SWIR_1\",\n",
    "        \"SWIR_2\",\n",
    "    ],\n",
    "    output_bands=[\n",
    "        \"BLUE\",\n",
    "        \"GREEN\",\n",
    "        \"RED\",\n",
    "        \"NIR_NARROW\",\n",
    "        \"SWIR_1\",\n",
    "        \"SWIR_2\",\n",
    "    ],\n",
    "    rgb_indices=[2, 1, 0],\n",
    "    train_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    val_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    test_data_root=\"datasets/hls_burn_scars/data\",\n",
    "    train_split=\"datasets/hls_burn_scars/splits/train.txt\",\n",
    "    val_split=\"datasets/hls_burn_scars/splits/val.txt\",\n",
    "    test_split=\"datasets/hls_burn_scars/splits/test.txt\",\n",
    "    img_grep=\"*_merged.tif\",\n",
    "    label_grep=\"*.mask.tif\",\n",
    "    means=[\n",
    "        0.033349706741586264,\n",
    "        0.05701185520536176,\n",
    "        0.05889748132001316,\n",
    "        0.2323245113436119,\n",
    "        0.1972854853760658,\n",
    "        0.11944914225186566,\n",
    "    ],\n",
    "    stds=[\n",
    "        0.02269135568823774,\n",
    "        0.026807560223070237,\n",
    "        0.04004109844362779,\n",
    "        0.07791732423672691,\n",
    "        0.08708738838140137,\n",
    "        0.07241979477437814,\n",
    "    ],\n",
    "    num_classes=2,\n",
    "    train_transform=[A.D4(), A.pytorch.ToTensorV2()],\n",
    "    test_transform=[A.pytorch.ToTensorV2()],\n",
    "    no_data_replace=0,\n",
    "    no_label_replace=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "        self.model = deeplabv3_mobilenet_v3_large(\n",
    "            weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        )\n",
    "        self.model.backbone[\"0\"][0] = nn.Conv2d(\n",
    "            num_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
    "        )\n",
    "        self.model.classifier[4] = nn.Conv2d(\n",
    "            256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        factory = EncoderDecoderFactory()\n",
    "        self.model = factory.build_model(\n",
    "            task=\"segmentation\",\n",
    "            backbone=\"prithvi_eo_v2_300\",\n",
    "            backbone_pretrained=True,\n",
    "            backbone_bands=[\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"],\n",
    "            necks=[\n",
    "                {\"name\": \"SelectIndices\", \"indices\": [5, 11, 17, 23]},\n",
    "                {\"name\": \"ReshapeTokensToImage\"},\n",
    "                {\"name\": \"LearnedInterpolateToPyramidal\"},\n",
    "            ],\n",
    "            decoder=\"UNetDecoder\",\n",
    "            decoder_channels=[512, 256, 128, 64],\n",
    "            num_classes=2,\n",
    "        )\n",
    "        checkpoint = torch.load(\n",
    "            \"teachers/Prithvi_EO_V2_300M_BurnScars.pt\", map_location=\"cpu\"\n",
    "        )\n",
    "        self.model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilPrithvi(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        soft_loss_weight=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.teacher = Teacher()\n",
    "        self.student = Student(num_channels=6)\n",
    "        self.soft_loss_func = nn.BCEWithLogitsLoss()\n",
    "        self.hard_loss_func = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceScore(num_classes=1)\n",
    "\n",
    "        self.soft_loss_weight = soft_loss_weight\n",
    "        self.teacher.eval()\n",
    "        self.teacher.requires_grad_(False)\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.student(image)[\"out\"]\n",
    "\n",
    "    def step(self, batch, stage):\n",
    "        image = batch[\"image\"]\n",
    "        mask = batch[\"mask\"].unsqueeze(1).float()\n",
    "\n",
    "        y = self.forward(image)\n",
    "\n",
    "        loss = self.hard_loss_func(y, mask)\n",
    "        self.log(f\"{stage}_loss\", loss, on_epoch=True)\n",
    "\n",
    "        y_dice = torch.sigmoid(y) > 0.5\n",
    "        self.log(f\"{stage}_dice\", self.dice(y_dice, mask), on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded weights for HLSBands.BLUE in position 0 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.GREEN in position 1 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.RED in position 2 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.NIR_NARROW in position 3 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_1 in position 4 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_2 in position 5 of patch embed\n"
     ]
    }
   ],
   "source": [
    "distilprithvi = DistilPrithvi(\n",
    "    soft_loss_weight=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/07 20:40:03 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.8.0.dev20250406+cu128. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n",
      "2025/04/07 20:40:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/mlflow/pytorch/_lightning_autolog.py:465: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.5.0.post0 and may not succeed with packages outside this range.\"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | teacher        | Teacher           | 324 M  | eval \n",
      "1 | student        | Student           | 11.0 M | train\n",
      "2 | soft_loss_func | BCEWithLogitsLoss | 0      | train\n",
      "3 | hard_loss_func | BCEWithLogitsLoss | 0      | train\n",
      "4 | dice           | DiceScore         | 0      | train\n",
      "-------------------------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "324 M     Non-trainable params\n",
      "335 M     Total params\n",
      "1,340.917 Total estimated model params size (MB)\n",
      "292       Modules in train mode\n",
      "589       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  62%|██████▎   | 10/16 [04:56<02:57,  0.03it/s, v_num=64]        \n",
      "Epoch 99: 100%|██████████| 16/16 [00:15<00:00,  1.03it/s, v_num=66]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 16/16 [00:19<00:00,  0.84it/s, v_num=66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/07 21:07:12 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0.dev20250406+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0.dev20250406' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/04/07 21:07:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 24. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_dice         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7795913815498352     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -7.8800482749938965    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_dice        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7795913815498352    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -7.8800482749938965   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    trainer.fit(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )\n",
    "    trainer.test(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
