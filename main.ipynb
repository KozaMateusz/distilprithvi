{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.segmentation import DiceScore \n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n",
    "import lightning as L\n",
    "from terratorch.cli_tools import LightningInferenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"configs/burn_scars_config.yaml\"\n",
    "CHECKPOINT = \"teachers/Prithvi_EO_V2_300M_BurnScars.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/cli.py:530: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--f=/run/user/1000/jupyter/runtime/kernel-v34139162d15361f8d75d69c1e9c940ba7e7b08826.json'], args=['--config', 'configs/burn_scars_config.yaml'].\n",
      "Seed set to 2\n",
      "INFO:root:Loaded weights for HLSBands.BLUE in position 0 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.GREEN in position 1 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.RED in position 2 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.NIR_NARROW in position 3 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_1 in position 4 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_2 in position 5 of patch embed\n",
      "WARNING:root:Decoder UNetDecoder does not have an `includes_head` attribute. Falling back to the value of the registry.\n",
      "/home/mateusz/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/cli.py:683: `SemanticSegmentationTask.configure_optimizers` will be overridden by `MyLightningCLI.configure_optimizers`.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inference_model = LightningInferenceModel.from_config(CONFIG, CHECKPOINT)\n",
    "teacher = inference_model.model\n",
    "datamodule = inference_model.datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = deeplabv3_mobilenet_v3_large(\n",
    "            weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        )\n",
    "        self.model.backbone[\"0\"][0] = nn.Conv2d(\n",
    "            num_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
    "        )\n",
    "        self.model.classifier[4] = nn.Conv2d(\n",
    "            256, num_classes, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilPrithvi(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        teacher,\n",
    "        student,\n",
    "        aug,\n",
    "        soft_loss_weight=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.teacher.eval()\n",
    "        self.teacher.requires_grad = False\n",
    "\n",
    "        self.student = student\n",
    "        # self.soft_loss_func = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        self.hard_loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.soft_loss_weight = soft_loss_weight\n",
    "\n",
    "        self.aug = aug\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student(x)[\"out\"]\n",
    "\n",
    "    def step(self, batch, stage):\n",
    "        # TODO: Might not be needed when training\n",
    "        # x = self.aug(batch)[\"image\"] \n",
    "\n",
    "        # TODO: used in the inference demo, idk why\n",
    "        if x.mean() > 1:\n",
    "            x = x / 10000\n",
    "\n",
    "        y = batch[\"mask\"]\n",
    "        y[y < 0] = 1  # interpret [no info] as [burn]\n",
    "\n",
    "        y_hat_s = self.student(x)[\"out\"]\n",
    "\n",
    "        loss = self.hard_loss_func(y_hat_s, y)\n",
    "        self.log(f\"{stage}_loss\", loss, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilprithvi = DistilPrithvi(\n",
    "    teacher=teacher,\n",
    "    student=Student(6, 2),\n",
    "    aug=datamodule.aug,\n",
    "    soft_loss_weight=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 21:02:13 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.6.0+cu124. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n",
      "2025/04/24 21:02:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/mateusz/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/pytorch/_lightning_autolog.py:465: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.5.0.post0 and may not succeed with packages outside this range.\"\n",
      "\n",
      "  | Name           | Type                     | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | teacher        | SemanticSegmentationTask | 324 M  | eval \n",
      "1 | student        | Student                  | 11.0 M | train\n",
      "2 | hard_loss_func | CrossEntropyLoss         | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "1,340.918 Total estimated model params size (MB)\n",
      "290       Modules in train mode\n",
      "618       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cf826710ee495d9a44e8877465dfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23601a6e6174279a9a6e99efa25aa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/optim/adamw.py:220\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mDistilPrithvi.training_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mDistilPrithvi.step\u001b[39m\u001b[34m(self, batch, stage)\u001b[39m\n\u001b[32m     35\u001b[39m y[y < \u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# interpret [no info] as [burn]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m y_hat_s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     39\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.hard_loss_func(y_hat_s, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mStudent.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torchvision/models/segmentation/_utils.py:23\u001b[39m, in \u001b[36m_SimpleSegmentationModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# contract: features is a dict of tensors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m result = OrderedDict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:69\u001b[39m, in \u001b[36mIntermediateLayerGetter.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items():\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     x = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m mlflow.pytorch.autolog()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilprithvi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     trainer.test(\n\u001b[32m      9\u001b[39m         distilprithvi,\n\u001b[32m     10\u001b[39m         datamodule,\n\u001b[32m     11\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    481\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:182\u001b[39m, in \u001b[36mwith_managed_run.<locals>.patch_with_managed_run\u001b[39m\u001b[34m(original, *args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     managed_run = create_managed_run()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     result = \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/pytorch/_lightning_autolog.py:539\u001b[39m, in \u001b[36mpatched_fit\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    532\u001b[39m         warnings.warn(\n\u001b[32m    533\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAutomatic model checkpointing is disabled because this feature only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    534\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msupports pytorch-lightning >= 1.6.0.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    535\u001b[39m         )\n\u001b[32m    537\u001b[39m client.flush(synchronous=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m early_stop_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    542\u001b[39m     _log_early_stop_metrics(early_stop_callback, client, run_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    423\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    468\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    469\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    trainer.fit(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )\n",
    "    trainer.test(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Union\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "import yaml\n",
    "from einops import rearrange\n",
    "from terratorch.cli_tools import LightningInferenceModel\n",
    "\n",
    "NO_DATA = -9999\n",
    "NO_DATA_FLOAT = 0.0001\n",
    "OFFSET = 0\n",
    "PERCENTILE = 99\n",
    "\n",
    "\n",
    "def process_channel_group(orig_img, channels):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        orig_img: torch.Tensor representing original image (reference) with shape = (bands, H, W).\n",
    "        channels: list of indices representing RGB channels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor with shape (num_channels, height, width) for original image\n",
    "    \"\"\"\n",
    "\n",
    "    orig_img = orig_img[channels, ...]\n",
    "    valid_mask = torch.ones_like(orig_img, dtype=torch.bool)\n",
    "    valid_mask[orig_img == NO_DATA_FLOAT] = False\n",
    "\n",
    "    # Rescale (enhancing contrast)\n",
    "    max_value = max(3000, np.percentile(orig_img[valid_mask], PERCENTILE))\n",
    "    min_value = OFFSET\n",
    "\n",
    "    orig_img = torch.clamp((orig_img - min_value) / (max_value - min_value), 0, 1)\n",
    "\n",
    "    # No data as zeros\n",
    "    orig_img[~valid_mask] = 0\n",
    "\n",
    "    return orig_img\n",
    "\n",
    "\n",
    "def read_geotiff(file_path: str):\n",
    "    \"\"\"Read all bands from *file_path* and return image + meta info.\n",
    "\n",
    "    Args:\n",
    "        file_path: path to image file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray with shape (bands, height, width)\n",
    "        meta info dict\n",
    "    \"\"\"\n",
    "\n",
    "    with rasterio.open(file_path) as src:\n",
    "        img = src.read()\n",
    "        meta = src.meta\n",
    "        try:\n",
    "            coords = src.lnglat()\n",
    "        except:\n",
    "            # Cannot read coords\n",
    "            coords = None\n",
    "\n",
    "    return img, meta, coords\n",
    "\n",
    "\n",
    "def save_geotiff(image, output_path: str, meta: dict):\n",
    "    \"\"\"Save multi-band image in Geotiff file.\n",
    "\n",
    "    Args:\n",
    "        image: np.ndarray with shape (bands, height, width)\n",
    "        output_path: path where to save the image\n",
    "        meta: dict with meta info.\n",
    "    \"\"\"\n",
    "\n",
    "    with rasterio.open(output_path, \"w\", **meta) as dest:\n",
    "        for i in range(image.shape[0]):\n",
    "            dest.write(image[i, :, :], i + 1)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def _convert_np_uint8(float_image: torch.Tensor):\n",
    "    image = float_image.numpy() * 255.0\n",
    "    image = image.astype(dtype=np.uint8)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_example(\n",
    "    file_paths: List[str],\n",
    "    mean: List[float] = None,\n",
    "    std: List[float] = None,\n",
    "    indices: Union[list[int], None] = None,\n",
    "):\n",
    "    \"\"\"Build an input example by loading images in *file_paths*.\n",
    "\n",
    "    Args:\n",
    "        file_paths: list of file paths .\n",
    "        mean: list containing mean values for each band in the images in *file_paths*.\n",
    "        std: list containing std values for each band in the images in *file_paths*.\n",
    "\n",
    "    Returns:\n",
    "        np.array containing created example\n",
    "        list of meta info for each image in *file_paths*\n",
    "    \"\"\"\n",
    "\n",
    "    imgs = []\n",
    "    metas = []\n",
    "    temporal_coords = []\n",
    "    location_coords = []\n",
    "\n",
    "    for file in file_paths:\n",
    "        img, meta, coords = read_geotiff(file)\n",
    "\n",
    "        # Rescaling (don't normalize on nodata)\n",
    "        img = np.moveaxis(img, 0, -1)  # channels last for rescaling\n",
    "        if indices is not None:\n",
    "            img = img[..., indices]\n",
    "        if mean is not None and std is not None:\n",
    "            img = np.where(img == NO_DATA, NO_DATA_FLOAT, (img - mean) / std)\n",
    "\n",
    "        imgs.append(img)\n",
    "        metas.append(meta)\n",
    "        if coords is not None:\n",
    "            location_coords.append(coords)\n",
    "\n",
    "        try:\n",
    "            match = re.search(r\"(\\d{7,8}T\\d{6})\", file)\n",
    "            if match:\n",
    "                year = int(match.group(1)[:4])\n",
    "                julian_day = match.group(1).split(\"T\")[0][4:]\n",
    "                if len(julian_day) == 3:\n",
    "                    julian_day = int(julian_day)\n",
    "                else:\n",
    "                    julian_day = (\n",
    "                        datetime.datetime.strptime(julian_day, \"%m%d\")\n",
    "                        .timetuple()\n",
    "                        .tm_yday\n",
    "                    )\n",
    "                temporal_coords.append([year, julian_day])\n",
    "        except Exception as e:\n",
    "            print(f\"Could not extract timestamp for {file} ({e})\")\n",
    "\n",
    "    imgs = np.stack(imgs, axis=0)  # num_frames, H, W, C\n",
    "    imgs = np.moveaxis(imgs, -1, 0).astype(\"float32\")  # C, num_frames, H, W\n",
    "    imgs = np.expand_dims(imgs, axis=0)  # add batch di\n",
    "\n",
    "    return imgs, temporal_coords, location_coords, metas\n",
    "\n",
    "\n",
    "def run_model(input_data, model, datamodule, img_size):\n",
    "    # Reflect pad if not divisible by img_size\n",
    "    original_h, original_w = input_data.shape[-2:]\n",
    "    pad_h = (img_size - (original_h % img_size)) % img_size\n",
    "    pad_w = (img_size - (original_w % img_size)) % img_size\n",
    "    input_data = np.pad(\n",
    "        input_data, ((0, 0), (0, 0), (0, 0), (0, pad_h), (0, pad_w)), mode=\"reflect\"\n",
    "    )\n",
    "\n",
    "    # Build sliding window\n",
    "\n",
    "    batch_size = 1\n",
    "    batch = torch.tensor(input_data, device=\"cpu\")\n",
    "    windows = batch.unfold(3, img_size, img_size).unfold(4, img_size, img_size)\n",
    "    h1, w1 = windows.shape[3:5]\n",
    "    windows = rearrange(\n",
    "        windows, \"b c t h1 w1 h w -> (b h1 w1) c t h w\", h=img_size, w=img_size\n",
    "    )\n",
    "\n",
    "    # Split into batches if number of windows > batch_size\n",
    "    num_batches = windows.shape[0] // batch_size if windows.shape[0] > batch_size else 1\n",
    "    windows = torch.tensor_split(windows, num_batches, dim=0)\n",
    "\n",
    "    # Run model\n",
    "    pred_imgs = []\n",
    "    for x in windows:\n",
    "        # Apply standardization\n",
    "        x = datamodule.test_transform(image=x.squeeze().numpy().transpose(1, 2, 0))\n",
    "        x[\"image\"] = x[\"image\"].unsqueeze(0)\n",
    "        x = datamodule.aug(x)[\"image\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = x.to(model.device)\n",
    "            pred = model(x)\n",
    "            pred = pred.output.detach().cpu()\n",
    "\n",
    "        y_hat = pred.argmax(dim=1)\n",
    "\n",
    "        y_hat = torch.nn.functional.interpolate(\n",
    "            y_hat.unsqueeze(1).float(), size=img_size, mode=\"nearest\"\n",
    "        )\n",
    "\n",
    "        pred_imgs.append(y_hat)\n",
    "\n",
    "    pred_imgs = torch.concat(pred_imgs, dim=0)\n",
    "\n",
    "    # Build images from patches\n",
    "    pred_imgs = rearrange(\n",
    "        pred_imgs,\n",
    "        \"(b h1 w1) c h w -> b c (h1 h) (w1 w)\",\n",
    "        h=img_size,\n",
    "        w=img_size,\n",
    "        b=1,\n",
    "        c=1,\n",
    "        h1=h1,\n",
    "        w1=w1,\n",
    "    )\n",
    "\n",
    "    # Cut padded area back to original size\n",
    "    pred_imgs = pred_imgs[..., :original_h, :original_w]\n",
    "\n",
    "    # Squeeze (batch size 1)\n",
    "    pred_imgs = pred_imgs[0]\n",
    "\n",
    "    return pred_imgs\n",
    "\n",
    "\n",
    "def main(\n",
    "    data_file: str,\n",
    "    config: str,\n",
    "    checkpoint: str,\n",
    "    output_dir: str,\n",
    "    rgb_outputs: bool,\n",
    "    input_indices: list[int] = None,\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(config, \"r\") as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "\n",
    "    # Load model ---------------------------------------------------------------------------------\n",
    "\n",
    "    lightning_model = LightningInferenceModel.from_config(config, checkpoint)\n",
    "    img_size = 512  # Size of BurnScars\n",
    "\n",
    "    # Loading data ---------------------------------------------------------------------------------\n",
    "\n",
    "    input_data, temporal_coords, location_coords, meta_data = load_example(\n",
    "        file_paths=[data_file],\n",
    "        indices=input_indices,\n",
    "    )\n",
    "\n",
    "    meta_data = meta_data[0]  # only one image\n",
    "\n",
    "    if input_data.mean() > 1:\n",
    "        input_data = input_data / 10000  # Convert to range 0-1\n",
    "\n",
    "    # Running model --------------------------------------------------------------------------------\n",
    "    print(input_data.shape)\n",
    "\n",
    "    lightning_model.model.eval()\n",
    "\n",
    "    channels = config_dict[\"data\"][\"init_args\"][\"rgb_indices\"]\n",
    "\n",
    "    pred = run_model(\n",
    "        input_data, lightning_model.model, lightning_model.datamodule, img_size\n",
    "    )\n",
    "    display_mask(pred.squeeze(0).squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_(x, model, datamodule):\n",
    "\n",
    "    n = {}\n",
    "    n[\"image\"] = x\n",
    "    x = datamodule.aug(n)[\"image\"]\n",
    "\n",
    "    pred = model(x)\n",
    "    pred = pred.output\n",
    "\n",
    "    y_hat = pred.argmax(dim=1)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def display_mask(x):\n",
    "    plt.imshow(x, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/cli.py:530: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--f=/run/user/1000/jupyter/runtime/kernel-v34139162d15361f8d75d69c1e9c940ba7e7b08826.json'], args=['--config', 'configs/burn_scars_config.yaml'].\n",
      "Seed set to 2\n",
      "INFO:root:Loaded weights for HLSBands.BLUE in position 0 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.GREEN in position 1 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.RED in position 2 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.NIR_NARROW in position 3 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_1 in position 4 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_2 in position 5 of patch embed\n",
      "WARNING:root:Decoder UNetDecoder does not have an `includes_head` attribute. Falling back to the value of the registry.\n",
      "/home/mateusz/Desktop/university/thesis/distilprithvi/venv/lib/python3.11/site-packages/lightning/pytorch/cli.py:683: `SemanticSegmentationTask.configure_optimizers` will be overridden by `MyLightningCLI.configure_optimizers`.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 1, 512, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.seed()\n",
    "teacher.eval()\n",
    "datamodule.setup(\"test\")\n",
    "idx = torch.randint(0, len(datamodule.test_dataset), (1,)).item()\n",
    "input_data = datamodule.test_dataset[idx][\"image\"]\n",
    "mask = datamodule.test_dataset[idx][\"mask\"]\n",
    "filename = datamodule.test_dataset[idx][\"filename\"]\n",
    "print(input_data.shape)\n",
    "input_data = input_data.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "if input_data.mean() > 1:\n",
    "    input_data = input_data / 10000  # Convert to range 0-1\n",
    "\n",
    "pred = run_model_(\n",
    "    input_data,\n",
    "    teacher,\n",
    "    datamodule,\n",
    ")\n",
    "\n",
    "main(\n",
    "    data_file=filename,\n",
    "    config=\"configs/burn_scars_config.yaml\",\n",
    "    checkpoint=\"teachers/Prithvi_EO_V2_300M_BurnScars.pt\",\n",
    "    output_dir=\"output\",\n",
    "    rgb_outputs=False,\n",
    "    input_indices=[0, 1, 2, 3, 4, 5],\n",
    ")\n",
    "display_mask(pred.squeeze(0).squeeze(0))\n",
    "display_mask(mask.squeeze(0).squeeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
