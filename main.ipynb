{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terratorch.cli_tools import LightningInferenceModel\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import (\n",
    "    deeplabv3_mobilenet_v3_large,\n",
    "    DeepLabV3_MobileNet_V3_Large_Weights,\n",
    ")\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"teachers/hls_burn_scars_teacher/burn_scars_config.yaml\"\n",
    "CHECKPOINT = \"teachers/hls_burn_scars_teacher/Prithvi_EO_V2_300M_BurnScars.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/lightning/pytorch/cli.py:530: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--f=/run/user/1003/jupyter/runtime/kernel-v3299645aeb3caefd4ec88db5fd8907a8a3bc06dc1.json'], args=['--config', 'teachers/hls_burn_scars_teacher/burn_scars_config.yaml'].\n",
      "Seed set to 2\n",
      "INFO:root:Loaded weights for HLSBands.BLUE in position 0 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.GREEN in position 1 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.RED in position 2 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.NIR_NARROW in position 3 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_1 in position 4 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_2 in position 5 of patch embed\n",
      "WARNING:root:Decoder UNetDecoder does not have an `includes_head` attribute. Falling back to the value of the registry.\n",
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/lightning/pytorch/cli.py:683: `SemanticSegmentationTask.configure_optimizers` will be overridden by `MyLightningCLI.configure_optimizers`.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inference_model = LightningInferenceModel.from_config(CONFIG, CHECKPOINT)\n",
    "teacher = inference_model.model\n",
    "datamodule = inference_model.datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabMobileNetV3Large(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = deeplabv3_mobilenet_v3_large(\n",
    "            weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        )\n",
    "        self.model.backbone[\"0\"][0] = nn.Conv2d(\n",
    "            num_channels,\n",
    "            16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.model.classifier[4] = nn.Conv2d(\n",
    "            256,\n",
    "            num_classes,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilPrithvi(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        teacher,\n",
    "        student,\n",
    "        kd_weight=0.5,\n",
    "        kd_temperature=2.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.teacher.eval()\n",
    "\n",
    "        self.student = student\n",
    "\n",
    "        self.kd_weight = kd_weight\n",
    "        self.kd_temperature = kd_temperature\n",
    "        self.kd_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "        self.metrics = {\n",
    "            \"train\": self.teacher.train_metrics,\n",
    "            \"val\": self.teacher.val_metrics,\n",
    "            \"test\": self.teacher.test_metrics[0],\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student(x)[\"out\"]\n",
    "\n",
    "    def _step(self, batch, stage):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "\n",
    "        y_hat_s = self(x)\n",
    "        loss_target = self.teacher.criterion(y_hat_s, y)\n",
    "\n",
    "        if self.kd_weight == 0:\n",
    "            loss = loss_target\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat_t = self.teacher(x).output\n",
    "\n",
    "            loss_kd = self.kd_criterion(\n",
    "                torch.log_softmax(y_hat_s / self.kd_temperature, dim=1),\n",
    "                torch.softmax(y_hat_t / self.kd_temperature, dim=1),\n",
    "            ) * (self.kd_temperature**2)\n",
    "\n",
    "            loss = self.kd_weight * loss_kd + (1 - self.kd_weight) * loss_target\n",
    "\n",
    "        self.metrics[stage].update(y_hat_s.argmax(dim=1), y)\n",
    "        self.log(f\"{stage}_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def _on_epoch_end(self, stage):\n",
    "        metrics = self.metrics[stage].compute()\n",
    "        self.log_dict(metrics, on_epoch=True, on_step=False)\n",
    "        self.metrics[stage].reset()\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        return self._step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        self._step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        self._step(batch, \"test\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self._on_epoch_end(\"train\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self._on_epoch_end(\"val\")\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self._on_epoch_end(\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilprithvi = DistilPrithvi(\n",
    "    teacher=teacher,\n",
    "    student=DeepLabMobileNetV3Large(\n",
    "        num_channels=len(datamodule.output_bands),\n",
    "        num_classes=datamodule.num_classes,\n",
    "    ),\n",
    "    kd_temperature=4.0,\n",
    "    kd_weight=0.75,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 15:53:37 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.8.0.dev20250430+cu128. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n",
      "2025/05/03 15:53:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/mlflow/pytorch/_lightning_autolog.py:465: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.5.0.post0 and may not succeed with packages outside this range.\"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                     | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | teacher      | SemanticSegmentationTask | 324 M  | eval \n",
      "1 | student      | DeepLabMobileNetV3Large  | 11.0 M | train\n",
      "2 | kd_criterion | KLDivLoss                | 0      | train\n",
      "------------------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "1,340.918 Total estimated model params size (MB)\n",
      "290       Modules in train mode\n",
      "618       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    trainer.fit(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )\n",
    "    trainer.test(\n",
    "        distilprithvi,\n",
    "        datamodule,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
