{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terratorch.cli_tools import LightningInferenceModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import (\n",
    "    deeplabv3_mobilenet_v3_large,\n",
    "    DeepLabV3_MobileNet_V3_Large_Weights,\n",
    ")\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"teachers/hls_burn_scars_teacher/burn_scars_config.yaml\"\n",
    "CHECKPOINT = \"teachers/hls_burn_scars_teacher/Prithvi_EO_V2_300M_BurnScars.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/lightning/pytorch/cli.py:530: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--f=/run/user/1003/jupyter/runtime/kernel-v388133463edcc071a288a755d17143d0c2631c103.json'], args=['--config', 'teachers/hls_burn_scars_teacher/burn_scars_config.yaml'].\n",
      "Seed set to 2\n",
      "INFO:root:Loaded weights for HLSBands.BLUE in position 0 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.GREEN in position 1 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.RED in position 2 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.NIR_NARROW in position 3 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_1 in position 4 of patch embed\n",
      "INFO:root:Loaded weights for HLSBands.SWIR_2 in position 5 of patch embed\n",
      "WARNING:root:Decoder UNetDecoder does not have an `includes_head` attribute. Falling back to the value of the registry.\n",
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/lightning/pytorch/cli.py:683: `SemanticSegmentationTask.configure_optimizers` will be overridden by `MyLightningCLI.configure_optimizers`.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inference_model = LightningInferenceModel.from_config(CONFIG, CHECKPOINT)\n",
    "teacher = inference_model.model\n",
    "datamodule = inference_model.datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabMobileNetV3Large(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = deeplabv3_mobilenet_v3_large(\n",
    "            weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        )\n",
    "        self.model.backbone[\"0\"][0] = nn.Conv2d(\n",
    "            num_channels,\n",
    "            16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.model.classifier[4] = nn.Conv2d(\n",
    "            256,\n",
    "            num_classes,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilPrithvi(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        teacher,\n",
    "        student,\n",
    "        kd_weight=0.5,\n",
    "        kd_temperature=2.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.teacher.eval()\n",
    "\n",
    "        self.student = student\n",
    "\n",
    "        self.kd_weight = kd_weight\n",
    "        self.kd_temperature = kd_temperature\n",
    "        self.kd_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student(x)[\"out\"]\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "\n",
    "        y_hat_s = self(x)\n",
    "        loss_target = self.teacher.criterion(y_hat_s, y)\n",
    "\n",
    "        if self.kd_weight == 0:\n",
    "            loss = loss_target\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat_t = self.teacher(x).output\n",
    "            loss_kd = self.kd_criterion(\n",
    "                torch.log_softmax(y_hat_s / self.kd_temperature, dim=1),\n",
    "                torch.softmax(y_hat_t / self.kd_temperature, dim=1),\n",
    "            ) * (self.kd_temperature**2)\n",
    "            self.log(\"train/loss_target\", loss_target, on_epoch=True, on_step=False)\n",
    "            self.log(\"train/loss_kd\", loss_kd, on_epoch=True, on_step=False)\n",
    "\n",
    "            loss = self.kd_weight * loss_kd + (1 - self.kd_weight) * loss_target\n",
    "\n",
    "        self.log(\"train/loss\", loss, on_epoch=True, on_step=False)\n",
    "        self.teacher.train_metrics.update(y_hat_s.argmax(dim=1), y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat_s = self(x)\n",
    "        loss = self.teacher.criterion(y_hat_s, y)\n",
    "        self.teacher.val_metrics.update(y_hat_s.argmax(dim=1), y)\n",
    "        self.log(\"val/loss\", loss, on_epoch=True, on_step=False)\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat_s = self(x)\n",
    "        loss = self.teacher.criterion(y_hat_s, y)\n",
    "        self.teacher.test_metrics[0].update(y_hat_s.argmax(dim=1), y)\n",
    "        self.log(\"test/loss\", loss, on_epoch=True, on_step=False)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.teacher.train_metrics.compute()\n",
    "        self.log_dict(metrics, on_epoch=True, on_step=False)\n",
    "        self.teacher.train_metrics.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.teacher.val_metrics.compute()\n",
    "        self.log_dict(metrics, on_epoch=True, on_step=False)\n",
    "        self.teacher.val_metrics.reset()\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        metrics = self.teacher.test_metrics[0].compute()\n",
    "        self.log_dict(metrics, on_epoch=True, on_step=False)\n",
    "        self.teacher.test_metrics[0].reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilprithvi = DistilPrithvi(\n",
    "    teacher=teacher,\n",
    "    student=DeepLabMobileNetV3Large(\n",
    "        num_channels=len(datamodule.output_bands),\n",
    "        num_classes=datamodule.num_classes,\n",
    "    ),\n",
    "    kd_temperature=4.0,\n",
    "    kd_weight=0.75,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "mlf_logger = L.pytorch.loggers.MLFlowLogger(\n",
    "    experiment_name=\"distilprithvi\",\n",
    "    run_name=\"distilprithvi\",\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(max_epochs=2, logger=mlf_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type                     | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | teacher      | SemanticSegmentationTask | 324 M  | eval \n",
      "1 | student      | DeepLabMobileNetV3Large  | 11.0 M | train\n",
      "2 | kd_criterion | KLDivLoss                | 0      | train\n",
      "------------------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "1,340.918 Total estimated model params size (MB)\n",
      "290       Modules in train mode\n",
      "618       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 18/18 [00:18<00:00,  0.99it/s, v_num=76ff]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkoza/workspace/ml/distilprithvi/venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassJaccardIndex was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 18/18 [00:18<00:00,  0.95it/s, v_num=76ff]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 18/18 [00:21<00:00,  0.84it/s, v_num=76ff]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 12.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">              Test metric               </span>┃<span style=\"font-weight: bold\">              DataLoader 0              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/Multiclass_Accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.8825483322143555           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/Multiclass_F1_Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.8825483322143555           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Multiclass_Jaccard_Index      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.48231783509254456           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/Multiclass_Jaccard_Index_Micro   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.7897866368293762           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">               test/loss                </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.41054394841194153           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/multiclassaccuracy_burn_scar    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.10242204368114471           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/multiclassaccuracy_not_burned   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.9733701944351196           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test/multiclassjaccardindex_burn_scar  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.08335535228252411           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test/multiclassjaccardindex_not_burned </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.8812803030014038           </span>│\n",
       "└────────────────────────────────────────┴────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m             Test metric              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m             DataLoader 0             \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/Multiclass_Accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.8825483322143555          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/Multiclass_F1_Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.8825483322143555          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/Multiclass_Jaccard_Index     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.48231783509254456          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/Multiclass_Jaccard_Index_Micro  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.7897866368293762          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m              test/loss               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.41054394841194153          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test/multiclassaccuracy_burn_scar   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.10242204368114471          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test/multiclassaccuracy_not_burned  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.9733701944351196          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest/multiclassjaccardindex_burn_scar \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.08335535228252411          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest/multiclassjaccardindex_not_burned\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.8812803030014038          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────┴────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 0.41054394841194153,\n",
       "  'test/Multiclass_Accuracy': 0.8825483322143555,\n",
       "  'test/multiclassaccuracy_not_burned': 0.9733701944351196,\n",
       "  'test/multiclassaccuracy_burn_scar': 0.10242204368114471,\n",
       "  'test/Multiclass_F1_Score': 0.8825483322143555,\n",
       "  'test/Multiclass_Jaccard_Index': 0.48231783509254456,\n",
       "  'test/multiclassjaccardindex_not_burned': 0.8812803030014038,\n",
       "  'test/multiclassjaccardindex_burn_scar': 0.08335535228252411,\n",
       "  'test/Multiclass_Jaccard_Index_Micro': 0.7897866368293762}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    distilprithvi,\n",
    "    datamodule,\n",
    ")\n",
    "trainer.test(\n",
    "    distilprithvi,\n",
    "    datamodule,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
